pf(1,df1 = 1,df2 = 1)
# Opgave 30
# 5
pf(1,df1 = 2,df2 = 2)
# Opgave 30
# 5
pf(-1,df1 = 2,df2 = 2)
# Opgave 30
# 5
pf(1,df1 = 1,df2 = 1)
read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
table read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
table <- read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
table = read.table("http://www-stat.stanford.edu/~tibs/ElemStatLearn/datasets/SAheart.data",
sep=",",head=T,row.names=1)
k <- 100000
## 1. Simulate k samples of each nA=9 and nB=9 exponentials with the
## right means and standard deviations
simAsamples <- replicate(k, rnorm(nA, mean(xA), sd(xA)))
simBsamples <- replicate(k, rnorm(nB, mean(xB), sd(xB)))
## 2. Compute the difference between the simulated medians k times
simDifmedians <- apply(simAsamples, 2, median) - apply(simBsamples, 2, median)
## 3. Find the two relevant quantiles of the k simulated differences of means
quantile(simDifmedians, c(0.025, 0.975))
## 3. Find the two relevant quantiles of the k simulated differences of means
quantile(simDifmedians, c(0.025, 0.975))
################################
# eNote 1 - Data Visualization #
################################
## Ikke super relevant
## Sample variance and standard deviation
var(x)
sqrt(var(x))
sd(x)
## Sample quartiles
quantile(x, type=2)
## Sample quantiles 0%, 10%,..,90%, 100%:
quantile(x, probs=seq(0, 1, by=0.10), type=2)
####################################
# eNote 2 - Probability simulation #
####################################
## Simulate a fair dice
## Number of simulated realizations
n <- 30
## Draw independently from the set (1,2,3,4,5,6) with equal probability
xFair <- sample(1:6, size=n, replace=TRUE)
## Simulate 30 successive dice rolls
Xfair <- sample(1:6, size=30, replace=TRUE)
## Count the number sixes obtained
sum(Xfair==6)
## This is equivalent to
rbinom(1, size=30, prob=1/6)
## Probability of x goals in 10 minutes with lambda rate
## The Poisson pdf
dpois(x=x, lambda=lambda)
## Use the cdf to calculate the probability of getting the observed
## sample standard deviation or higher
1 - pchisq(chiSqValue, df=n-1)
################################################
# eNote 3 - Statistics under normal assumption #
################################################
## 1.96 is standard
## The P(T>1.96) probability  for n=10
1 - pt(1.96, df = 9)
## The P(Z>1.96) probability
1 - pnorm(1.96)
## The standard normal 0.975% quantile (0.05 conf.level)
qnorm(0.975)
## The t-quantiles for n=10:
qt(0.975, 9)
## The 99% confidence interval for the mean, one sample
A <- c(8.360, 6.377,  7.385, 6.245, 8.766, 6.848, 6.074, 6.310, 5.946, 8.270)
t.test(A, conf.level = 0.99)
## The 99% confidence interval for the mean, two samples
A <- c(8.360, 6.377,  7.385, 6.245, 8.766, 6.848, 6.074, 6.310, 5.946, 8.270)
B <- c(8.806, 6.513, 10.209, 5.495, 6.513, 8.529, 8.354, 5.681, 7.553, 6.834)
t.test(A,B,conf.level = 0.99)
### Example
## Enter sleep difference observations
x <- c(1.2, 2.4, 1.3, 1.3, 0.9, 1.0, 1.8, 0.8, 4.6, 1.4)
n <- length(x)
## Compute the tobs - the observed test statistic
tobs <- (mean(x) - 0) / (sd(x) / sqrt(n))
tobs
## Compute the p-value as a tail-probability in the t-distribution
pvalue <- 2 * (1-pt(abs(tobs), df=n-1))
pvalue
t.test(x)
## The probability of observed greater that t_obs
1 - pt(t_obs, df = nu)
## Finding the power of detecting a group difference of 2
## with sigma=1 for n=10
power.t.test(n=10, delta=2, sd=1, sig.level=0.05)
## Finding the sample size for detecting a group difference of 2
## with sigma=1 and power=0.9
power.t.test(power=0.90, delta=2, sd=1, sig.level=0.05)
## Finding the detectable effect size (delta)
## with sigma=1, n=10 and power=0.9
power.t.test(power=0.90, n=10, sd=1, sig.level=0.05)
#########################################
# eNote 4 - Simulation based statistics #
#########################################
################################################################
## Nutrition study: comparing medians assuming normal distributions
##
## Read the data
xA <- c(7.53, 7.48, 8.08, 8.09, 10.15, 8.4, 10.88, 6.13, 7.9)
xB <- c(9.21, 11.51, 12.79, 11.85, 9.97, 8.79, 9.69, 9.68, 9.19)
nA <- length(xA)
nB <- length(xB)
set.seed(9843)
## Set the number of simulations
k <- 100000
## 1. Simulate k samples of each nA=9 and nB=9 exponentials with the
## right means and standard deviations
simAsamples <- replicate(k, rnorm(nA, mean(xA), sd(xA)))
simBsamples <- replicate(k, rnorm(nB, mean(xB), sd(xB)))
## 2. Compute the difference between the simulated medians k times
simDifmedians <- apply(simAsamples, 2, median) - apply(simBsamples, 2, median)
## 3. Find the two relevant quantiles of the k simulated differences of means
quantile(simDifmedians, c(0.025, 0.975))
## Install the bootstrap package
install.packages("bootstrap")
## Calculate the 95% CI for the Teech and bottle example above
library(bootstrap)
quantile(bootstrap(simmeandifs,k,mean)$thetastar, c(0.025,0.975))
######################################
# eNote 5 - Simple linear regression #
######################################
## Read data
x <- c(168, 161, 167, 179, 184, 166, 198, 187, 191, 179)
y <- c(65.5, 58.3, 68.1, 85.7, 80.5, 63.4, 102.6, 91.4, 86.7, 78.9)
## Calculate averages
xbar <- mean(x)
ybar <- mean(y)
## Parameters estimates
Sxx <- sum((x - xbar)^2)
beta1hat <- sum((x - xbar)*(y - ybar)) / Sxx
beta0hat <- ybar - beta1hat * xbar
D <- data.frame(x=x, y=y)
fitStudents <- lm(y ~ x, data=D)
summary(fitStudents)
## Confidence intervals
confint(fit, level = 0.95)
beta0 <- coef(fitStudents)[1]
beta1 <- coef(fitStudents)[2]
########################################
# eNote 6 - Multiple linear regression #
########################################
## Read data
x1 <- c(0.083, 0.409, 0.515, 0.397, 0.223, 0.292, 0.584, 0.491, 0.923,
0.280, 0.772, 0.857, 0.758, 0.850, 0.409, 0.055, 0.578, 0.745,
0.886, 0.031)
x2 <- c(0.625, 0.604, 0.077, 0.414, 0.343, 0.202, 0.840, 0.266, 0.831,
0.385, 0.821, 0.308, 0.440, 0.865, 0.111, 0.970, 0.192, 0.939,
0.149, 0.318)
y <- c(0.156, 1.234, 0.490, 1.649, 0.500, 0.395, 1.452, 0.416, 1.390,
0.234, 1.574, 0.349, 1.287, 1.709, 0.323, 1.201, 1.210, 1.787,
0.591, 0.110)
## Parameter estimation
fit <- lm(y ~ x1 + x2)
## Summary of fit (parameter estimates, standard error, p-values, etc.)
summary(fit)
## Confidence intervals
confint(fit, level = 0.95)
## Use same commands as single linear regression otherwise
## Just be aware of the multiple variables present
##########################################
# eNote 7 - Proportions frequency tables #
##########################################
## TESTING THE PROBABILITY = 0.5 WITH A TWO-SIDED ALTERNATIVE
## WE HAVE OBSERVED 518 OUT OF 1154
## WITHOUT CONTINUITY CORRECTIONS
prop.test(x=518, n=1154, p = 0.5, correct = FALSE)
## TESTING THAT THE PROBABILITIES FOR THE TWO GROUPS ARE EQUAL
## CALCULATING 99% CONFINDECE INTERVAL
prop.test(x=c(23,35), n=c(57,167), correct=FALSE, conf.level=0.99)
## EXAMPLE
pill.study <- matrix(c(23, 35, 34, 132), ncol = 2, byrow = TRUE)
rownames(pill.study) <- c("Blood Clot", "No Clot")
colnames(pill.study) <- c("Pill", "No pill")
pill.study
# CHI2 TEST FOR TESTING THE PROBABILITIES FOR THE TWO GROUPS ARE EQUAL
chisq.test(pill.study, correct = FALSE)
#IF WE WANT THE EXPECTED NUMBERS SAVE result IN AN OBJECT
chi <- chisq.test(pill.study, correct = FALSE)
#THE EXPECTED VALUES
chi$expected
#THE CONTRIBUTIONS
contrib <- 100*chi$residuals^2/chi$statistic
contrib
library(corrplot)
corrplot(contrib, is.cor = FALSE)
#########################################
# eNote 8 - Statistics Multigroup ANOVA #
#########################################
## One Way ANOVA
k <- 5; n <- 10
SStr <- 7.3; SSbl <- 77.5; SSE <-  89.1
MStr <- SStr/(k-1)
MSE <- SSE/n-k
Ftr <- MStr/MSE
(1-pf(abs(Ftr),k-1,(k-1)*(l-1))); (1-pf(abs(Fbl),l-1,(k-1)*(l-1)))
SST <- SStr + SSbl + SSE
## Two Way ANOVA
k <- 5; l <- 8
SStr <- 7.3; SSbl <- 77.5; SSE <-  89.1
MStr <- SStr/(k-1); MSbl <- SSbl/(l-1)
MSE <- SSE/((k-1)*(l-1))
Ftr <- MStr/MSE; Fbl <- MSbl/MSE
(1-pf(abs(Ftr),k-1,(k-1)*(l-1))); (1-pf(abs(Fbl),l-1,(k-1)*(l-1)))
SST <- SStr + SSbl + SSE
## Explained variance
1-(SSE/SST)
## Example
y <- c(2.8, 3.6, 3.4, 2.3,
5.5, 6.3, 6.1, 5.7,
5.8, 8.3, 6.9, 6.1)
treatm <- factor(c(1, 1, 1, 1,
2, 2, 2, 2,
3, 3, 3, 3))
plot(treatm,y)
mu <- mean(y)
muis <- tapply(y, treatm, mean)
alpha <- muis - mu
mu
muis
alpha
tapply(y, treatm, var)
SST <- sum((y - mu)^2)
SSE <- sum((y[treatm==1] - muis[1])^2)+
sum((y[treatm==2] - muis[2])^2)+
sum((y[treatm==3] - muis[3])^2)
SSTr <- 4 * sum(alpha^2)
c(SST, SSE, SSTr)
vars <- tapply(y, treatm, var)
(12-3)*mean(vars)
x<-seq(0,5,by=0.01)
plot(x,df(x,df1=2,df2=9),type="l", xlab="$x$", ylab="pdf")
lines(x,df(x,df1=4,df2=9),col=2)
F <- (SSTr/(3 - 1)/(SSE/(12 - 3)))
pv <- 1 - pf(F, df1 = 3 - 1, df2 = 12 - 3)
c(F , pv)
anova(lm(y ~ treatm))
muis[1] - muis[2] + c(-1, 1) *
qt(0.975, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
tobs <- (muis[1] - muis[2])/sqrt(SSE/(12 - 3) * (1/4 + 1/4))
2 * (1 - pt(abs(tobs), 9))
alphaBonf <- 0.05/3
## A-B
alpha[1] - alpha[2] + c(-1, 1) *
qt(1-alphaBonf/2, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
## A-C
alpha[1] - alpha[3] + c(-1, 1) *
qt(1-alphaBonf/2, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
## B-C
alpha[2] - alpha[3] + c(-1, 1) *
qt(1-alphaBonf/2, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
c(qt(1 - alphaBonf/2, 9), qt(0.975, 9))
residuals <- lm(y ~ treatm)$residuals
qqnorm(residuals)
qqline(residuals)
residuals
y <- c(2.8, 3.6, 3.4, 2.3,
5.5, 6.3, 6.1, 5.7,
5.8, 8.3, 6.9, 6.1)
treatm <- factor(c(1, 1, 1, 1,
2, 2, 2, 2,
3, 3, 3, 3))
plot(as.numeric(treatm), y, pch=19, xlim=c(0.5, 3.5), axes=FALSE, xlab="Treatment", ylab="", cex=0.7)
lines(c(0,4),c(1,1)*mean(y),col=2)
lines(c(1,1),c(mean(y),mean(y[treatm==1])),col="blue")
lines(c(2,2),c(mean(y),mean(y[treatm==2])),col="blue")
lines(c(3,3),c(mean(y),mean(y[treatm==3])),col="blue")
box()
axis(1,at=c(1,2,3),labels=c("1","2","3"))
axis(2,at=c(mean(y),mean(y[treatm==1]),mean(y[treatm==2]),mean(y[treatm==3])),labels=c("$\\hat{\\mu}$","$\\hat{\\mu}_{1}$","$\\hat{\\mu}_{2}$","$\\hat{\\mu}_{3}$"), las=1)
points(c(1,2,3),c(mean(y[treatm==1]),mean(y[treatm==2]),mean(y[treatm==3])),pch=19,col=2,cex=1.2)
text(1,(mean(y)+mean(y[treatm==1]))/2,labels="$\\hat{\\alpha}_1$",adj=c(-1,0),col="blue")
text(2,(mean(y)+mean(y[treatm==2]))/2,labels="$\\hat{\\alpha}_2$",adj=c(-1,0),col="blue")
text(3,(mean(y)+mean(y[treatm==3]))/2,labels="$\\hat{\\alpha}_3$",adj=c(-1,0),col="blue")
text(1,min(y),labels="$y_{1,j}$",adj=c(-1,0),col=1)
y <- c(2.8, 3.6, 3.4, 2.3,
5.5, 6.3, 6.1, 5.7,
5.8, 8.3, 6.9, 6.1)
treatm <- factor(c(1, 1, 1, 1,
2, 2, 2, 2,
3, 3, 3, 3))
plot(treatm,y)
mu <- mean(y)
muis <- tapply(y, treatm, mean)
alpha <- muis - mu
mu
muis
alpha
tapply(y, treatm, var)
SST <- sum((y - mu)^2)
SSE <- sum((y[treatm==1] - muis[1])^2)+
sum((y[treatm==2] - muis[2])^2)+
sum((y[treatm==3] - muis[3])^2)
SSTr <- 4 * sum(alpha^2)
c(SST, SSE, SSTr)
vars <- tapply(y, treatm, var)
(12-3)*mean(vars)
x<-seq(0,5,by=0.01)
plot(x,df(x,df1=2,df2=9),type="l", xlab="$x$", ylab="pdf")
lines(x,df(x,df1=4,df2=9),col=2)
F <- (SSTr/(3 - 1)/(SSE/(12 - 3)))
pv <- 1 - pf(F, df1 = 3 - 1, df2 = 12 - 3)
c(F , pv)
anova(lm(y ~ treatm))
muis[1] - muis[2] + c(-1, 1) *
qt(0.975, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
tobs <- (muis[1] - muis[2])/sqrt(SSE/(12 - 3) * (1/4 + 1/4))
2 * (1 - pt(abs(tobs), 9))
alphaBonf <- 0.05/3
## A-B
alpha[1] - alpha[2] + c(-1, 1) *
qt(1-alphaBonf/2, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
## A-C
alpha[1] - alpha[3] + c(-1, 1) *
qt(1-alphaBonf/2, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
## B-C
alpha[2] - alpha[3] + c(-1, 1) *
qt(1-alphaBonf/2, df = 12 - 3) * sqrt(SSE/(12 - 3) * (1/4 + 1/4))
c(qt(1 - alphaBonf/2, 9), qt(0.975, 9))
residuals <- lm(y ~ treatm)$residuals
qqnorm(residuals)
qqline(residuals)
residuals
D <- data.frame(
strength=c(44.6, 52.8, 53.1, 51.5, 48.2, 50.5, 58.3, 50.0, 53.7, 40.8,
46.3, 55.4, 54.4, 50.5, 44.5, 48.5, 57.4, 55.3, 54.4, 43.9,
45.2, 58.1, 50.6, 47.5, 45.9, 52.3, 54.6, 53.4, 47.8, 42.5),
plastictype=factor(rep(1:5, 6))
)
plot(D$plastictype, D$strength, xlab="Plastictype", ylab="Strength")
fit <- lm(strength ~ plastictype, data=D)
anova(fit)
library(xtable)
print(xtable(anova(fit)))
qqnorm(fit$residuals)
qqline(fit$residuals)
set.seed(138)
library(MESS)
qqwrap <- function(x, y, ...){
stdy <- (y-mean(y))/sd(y)
qqnorm(stdy, main="", ...)
qqline(stdy)}
wallyplot(fit$residuals, FUN=qqwrap, ylim=c(-3,3))
tapply(D$strength, D$plastictype, mean)
LSD_0.005 <- qt(0.9975, 25) * sqrt(2*6.74/6)
LSD_0.005
y <- c(2.8, 3.6, 3.4, 2.3,
5.5, 6.3, 6.1, 5.7,
5.8, 8.3, 6.9, 6.1)
treatm <- factor(c(1, 1, 1, 1,
2, 2, 2, 2,
3, 3, 3, 3))
block <- factor(c(1, 2, 3, 4,
1, 2, 3, 4,
1, 2, 3, 4))
mu <- mean(y)
alpha <- tapply(y, treatm, mean) - mu
beta <- tapply(y, block, mean)  - mu
mu
alpha
beta
SSBl <- 3 * sum(beta^2)
SSE <- SST - SSTr - SSBl
c(SST, SSE, SSTr, SSBl)
## Test statistics
Ftr <- SSTr / (3-1) / ( SSE / ((3-1) * (4-1)))
Fbl <- SSBl / (4-1) / ( SSE / ((3-1) * (4-1)))
## p-values
pv.tr <- 1 - pf(Ftr, df1=3-1, df2=(3-1)*(4-1))
pv.bl <- 1 - pf(Fbl, df1=4-1, df2=(3-1)*(4-1))
c(Ftr, Fbl)
c(pv.tr, pv.bl)
D <- data.frame(treatm, block, y)
fit <- lm(y ~ treatm + block, data=D)
anova(fit)
muis[1] - muis[2] + c(-1,1) * qt(0.975, df=(4-1)*(3-1)) *
sqrt(SSE/((4-1)*(3-1)) * (1/4+1/4))
tobs <- (muis[1] - muis[2])/sqrt(SSE/6 * (1/4 + 1/4))
2 * (1 - pt(abs(tobs), df=6))
alphaBonf <- 0.05/3
## A vs. B
alpha[1] - alpha[2] + c(-1, 1) *
qt(1-alphaBonf/2, df = 6) * sqrt(SSE/6 * (1/4 + 1/4))
## A vs. C
alpha[1] - alpha[3] + c(-1, 1) *
qt(1-alphaBonf/2, df = 6) * sqrt(SSE/6 * (1/4 + 1/4))
## B vs. C
alpha[2] - alpha[3] + c(-1, 1) *
qt(1-alphaBonf/2, df = 6) * sqrt(SSE/6 * (1/4 + 1/4))
qqnorm(fit$residuals)
qqline(fit$residuals)
fit$residuals
par(mfrow=c(1,2))
plot(D$treatm, fit$residuals, xlab="Treatment", ylab="Residuals")
plot(D$block, fit$residuals, xlab="Block", ylab="Residuals")
## Collecting the data in a data frame
D <- data.frame(
y=c(22.5, 24.3, 24.9, 22.4,
21.5, 21.3, 23.9, 18.4,
22.2, 21.9, 21.7, 17.9),
car=factor(c(1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4)),
tire=factor(c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3))
)
par(mfrow=c(1,2))
plot(D$tire, D$y, xlab="Tire", ylab="y")
plot(D$car, D$y, xlab="Car", ylab="y")
fit <- lm(y ~ car + tire, data=D)
anova(fit)
qqnorm(fit$residuals)
qqline(fit$residuals)
par(mfrow=c(1,2))
plot(D$car, fit$residuals, xlab="Car", ylab="Residuals")
plot(D$tire, fit$residuals, xlab="Tire", ylab="Residuals")
tapply(D$y, D$tire, mean)
LSD_bonf <- qt(1-0.05/6, df=6) * sqrt(2*1.19/4)
LSD_bonf
AccDGT  <- predDGT %>% group_by(Fold) %>%
summarise(RMSEDGT = sqrt(mean((day30 - pred)^2)))
solve(3,9)
quad <- function(a, b, c)
{
a <- as.complex(a)
answer <- c((-b + sqrt(b^2 - 4 * a * c)) / (2 * a),
(-b - sqrt(b^2 - 4 * a * c)) / (2 * a))
if(all(Im(answer) == 0)) answer <- Re(answer)
if(answer[1] == answer[2]) return(answer[1])
answer
}
quad(1,2,3)
quad(1,2,0)
source("~/Desktop/DTU/2. semester/Matstat/Stat/eNote_kode.R")
setwd("~/Desktop/DTU/4. semester/Active Machine Learning and Agency/Project3")
data <- read.csv("/sample/data_435")
data <- read.csv("/sample/data_435")
data <- read.csv("sample/data_435")
library(readr)
data_435 <- read_csv("sample/data_435.csv")
View(data_435)
data_435 <- read_csv("sample/data_435.csv")
View(data_435)
hist(data_435)
hist(data_435['A'])
library(readr)
data <- read_csv("sample/data_435.csv")
View(data)
data[1]
data[2]
hist(data[2])
data[2]
hist(data[2].values())
hist(data$A)
hist(data$B)
hist(data$C)
hist(data$D)
fiti <- lm(A ~ B , data = data)
interact_plot(fiti, pred = A, modx = B)
library(jtools) # for summ()
data <- read_csv("sample/data_435.csv")
View(data)
fiti <- lm(A ~ B , data = data)
interact_plot(fiti, pred = A, modx = B)
library(ggplot2)
fiti <- lm(A ~ B , data = data)
interact_plot(fiti, pred = A, modx = B)
interact_plot(fiti)
interact(fiti)
library(interactions)
fiti <- lm(A ~ B , data = data)
interact(fiti)
interact:plot(fiti)
interact_plot(fiti)
interact_plot(fiti, pred = A, modx = B)
interact_plot(fiti, pred = A, modx = B)
fiti <- lm(A ~ B , data = data)
interact_plot(fiti, pred = A, modx = B)
interaction.plot(fiti, pred = A, modx = B)
interaction.plot(fiti)
fiti <- lm(A ~ B + C, data = data)
interaction.plot(data, c(A, B), fiti)
interaction.plot(data, c(data$A, data$B), fiti)
interaction.plot(, c(data$A, data$B), fiti)
interaction.plot(data$A, c(data$A, data$B), fiti)
interaction.plot(data$A, data$B, data$C)
interaction.plot(data$A, data$B)
interaction.plot(data$A, data$B, fiti)
interaction.plot(data$A, data$B, data$C)
interaction.plot(data$A, data$B, data$X1)
par(mfrow=c(3,1))
hist(data$A)
par(mfrow=c(2,2))
hist(data$A)
hist(dataint$A)
dataint <- read_csv("sample/data_518.csv")
par(mfrow=c(2,2))
hist(data$A)
hist(dataint$A)
hist(data$B)
hist(dataint$B)
hist(data$C)
hist(dataint$C)
hist(data$D)
hist(dataint$D)
